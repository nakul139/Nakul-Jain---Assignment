# ğŸ“° ReactJS Web Scraper App with Google OAuth

A modern ReactJS application that allows users to **log in with Google**, **scrape public website data (news headlines)**, and view it in a beautifully styled and responsive UI. Built with **React.js**, **Node.js**, **Python (BeautifulSoup)**, and **Tailwind CSS**.

---

## ğŸš€ Features

- ğŸ” **Google OAuth 2.0 Authentication**
- ğŸ•¸ï¸ **Web Scraping using Python (BeautifulSoup)**
- ğŸ“Š **Displays scraped data in React UI**
- ğŸ”„ **Real-time Refresh Button**
- ğŸ¨ **Clean, modern UI with Tailwind CSS**
- ğŸ’¡ **Fully responsive layout**

---

## ğŸ› ï¸ Tech Stack

| Frontend        | Backend           | Scraper                | Styling      |
| --------------- | ----------------- | ---------------------- | ------------ |
| React.js (Vite) | Node.js (Express) | Python (BeautifulSoup) | Tailwind CSS |

---

## ğŸ“‚ Folder Structure

react-scraper-app/
â”œâ”€â”€ Frontend/       # React + Tailwind frontend
â”œâ”€â”€ server/         # Express.js backend and Python scraper
â”‚   â””â”€â”€ scraper.py  # Uses BeautifulSoup to scrape data
â”œâ”€â”€ README.md

---

## ğŸ” Google OAuth Setup

1. Go to [Google Cloud Console](https://console.cloud.google.com/).
2. Create a new project and configure **OAuth 2.0 credentials**.
3. Add `http://localhost:5173` as an authorized redirect URI.
4. Copy your **Client ID** and replace in `main.jsx`:

```jsx
<GoogleOAuthProvider clientId="YOUR_CLIENT_ID">
ğŸ’» Local Development Setup
ğŸ§± Prerequisites
Node.js v18+

Python 3+

pip install beautifulsoup4 requests

âš™ï¸ Clone the repository
git clone https://github.com/nakul139/Nakul-Jain-Assignment.git
cd react-scraper-app

1. Start Backend Server
cd server
npm install
node server.js

2. Start Frontend (React)
cd ../Frontend
npm install
npm run dev

App will run at: http://localhost:5173


ğŸ¤ Connect with Me
ğŸ‘¤ Nakul Jain
ğŸ“§ jainnakul543@gmail.com
ğŸ”— https://www.linkedin.com/in/nakul-j/
ğŸ’» https://github.com/nakul139/

```
